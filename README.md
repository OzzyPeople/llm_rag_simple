A small Retrieval-Augmented Generation (RAG) service built with FastAPI, LangChain, and Gemini, that answers questions about stock market reports (e.g., Stock_Market_Performance_2024.pdf).

Project structure:

POC_RAG/
â”œâ”€ data/                        # PDFs or other documents
â”‚   â””â”€ Stock_Market_Performance_2024.pdf
â”œâ”€ chroma_db/                   # Vector store (persisted embeddings)
â”œâ”€ src/
â”‚   â”œâ”€ api/                     # FastAPI application
â”‚   â”‚   â”œâ”€ main.py              # App entrypoint
â”‚   â”‚   â”œâ”€ deps.py              # Loads RAG pipeline (vectorstore, retriever, LLM)
â”‚   â”‚   â””â”€ routes/
â”‚   â”‚       â””â”€ stock.py         # /stock/ask endpoint
â”‚   â”œâ”€ llm_poc/                 # RAG core logic
â”‚   â”‚   â”œâ”€ pipeline.py          # Build and persist vectorstore
â”‚   â”‚   â””â”€ llm.py               # LLM configuration
â”‚   â”œâ”€ retrievers/              # Retriever definitions
â”‚   â””â”€ utils/                   # Utility modules
â”œâ”€ pyproject.toml
â””â”€ README.md

SET UP

# 1. Activate Poetry environment
cd POC_RAG
poetry install
poetry shell

# 2. Run FastAPI
uvicorn src.api.main:app --reload --host 0.0.0.0 --port 8080

Tech Stack

FastAPI â€” lightweight API framework
LangChain â€” document loaders, retrievers, chains
ChromaDB â€” local vector database
Google Gemini / Anthropic Claude â€” LLMs for QA
PyMuPDF / pdfplumber â€” PDF parsing

Testing

Swagger UI â†’ http://127.0.0.1:8080/docs
ReDoc â†’ http://127.0.0.1:8080/redoc

ðŸ“Œ Next Steps

Add multiple document ingestion.
Return page references in answers.
Integrate re-ranking (MMR / cross-encoder).
Deploy to Cloud Run or AWS Lambda.